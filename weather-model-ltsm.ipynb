{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12911704,"sourceType":"datasetVersion","datasetId":8169753}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T10:56:40.161074Z","iopub.execute_input":"2025-08-30T10:56:40.161278Z","iopub.status.idle":"2025-08-30T10:56:41.402547Z","shell.execute_reply.started":"2025-08-30T10:56:40.161261Z","shell.execute_reply":"2025-08-30T10:56:41.401884Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/weather-features1/weather_features.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# CSV dosyasını DataFrame olarak okuma\ndf = pd.read_csv('/kaggle/input/weather-features1/weather_features.csv')\n\n# İlk birkaç satırı görüntüleme\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T10:56:41.403451Z","iopub.execute_input":"2025-08-30T10:56:41.403905Z","iopub.status.idle":"2025-08-30T10:56:42.094167Z","shell.execute_reply.started":"2025-08-30T10:56:41.403878Z","shell.execute_reply":"2025-08-30T10:56:42.093429Z"}},"outputs":[{"name":"stdout","text":"                      dt_iso city_name     temp  temp_min  temp_max  pressure  \\\n0  2015-01-01 00:00:00+01:00  Valencia  270.475   270.475   270.475      1001   \n1  2015-01-01 01:00:00+01:00  Valencia  270.475   270.475   270.475      1001   \n2  2015-01-01 02:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n3  2015-01-01 03:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n4  2015-01-01 04:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n\n   humidity  wind_speed  wind_deg  rain_1h  rain_3h  snow_3h  clouds_all  \\\n0        77           1        62      0.0      0.0      0.0           0   \n1        77           1        62      0.0      0.0      0.0           0   \n2        78           0        23      0.0      0.0      0.0           0   \n3        78           0        23      0.0      0.0      0.0           0   \n4        78           0        23      0.0      0.0      0.0           0   \n\n   weather_id weather_main weather_description weather_icon  \n0         800        clear        sky is clear          01n  \n1         800        clear        sky is clear          01n  \n2         800        clear        sky is clear          01n  \n3         800        clear        sky is clear          01n  \n4         800        clear        sky is clear          01n  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Tüm sütun isimlerini küçük harfe çevirme ve boşlukları alt çizgi ile değiştirme\ndf.columns = df.columns.str.lower().str.replace(' ', '_')\n\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T10:57:36.257029Z","iopub.execute_input":"2025-08-30T10:57:36.257724Z","iopub.status.idle":"2025-08-30T10:57:36.264336Z","shell.execute_reply.started":"2025-08-30T10:57:36.257677Z","shell.execute_reply":"2025-08-30T10:57:36.263636Z"}},"outputs":[{"name":"stdout","text":"Index(['dt_iso', 'city_name', 'temp', 'temp_min', 'temp_max', 'pressure',\n       'humidity', 'wind_speed', 'wind_deg', 'rain_1h', 'rain_3h', 'snow_3h',\n       'clouds_all', 'weather_id', 'weather_main', 'weather_description',\n       'weather_icon'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 'city_name' sütununun veri tipini bulma\nprint(\"city_name sütununun veri tipi:\", df['city_name'].dtype)\n\n# 'city_name' sütunundaki tekil şehir sayısını bulma\nprint(\"city_name sütunundaki tekil şehir sayısı:\", df['city_name'].nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T10:59:58.025885Z","iopub.execute_input":"2025-08-30T10:59:58.026572Z","iopub.status.idle":"2025-08-30T10:59:58.041763Z","shell.execute_reply.started":"2025-08-30T10:59:58.026548Z","shell.execute_reply":"2025-08-30T10:59:58.041110Z"}},"outputs":[{"name":"stdout","text":"city_name sütununun veri tipi: object\ncity_name sütunundaki tekil şehir sayısı: 5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# 'city_name' sütunundaki eşsiz değerleri (şehir isimlerini) listeleme\nprint(\"Veri setindeki 5 şehir:\")\nprint(df['city_name'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:00:02.328414Z","iopub.execute_input":"2025-08-30T11:00:02.328858Z","iopub.status.idle":"2025-08-30T11:00:02.339346Z","shell.execute_reply.started":"2025-08-30T11:00:02.328834Z","shell.execute_reply":"2025-08-30T11:00:02.338735Z"}},"outputs":[{"name":"stdout","text":"Veri setindeki 5 şehir:\n['Valencia' 'Madrid' 'Bilbao' ' Barcelona' 'Seville']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Her bir şehrin kaç kez geçtiğini sayma\nprint(\"Her bir şehirden kaç adet veri var:\")\nprint(df['city_name'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:00:06.549623Z","iopub.execute_input":"2025-08-30T11:00:06.549958Z","iopub.status.idle":"2025-08-30T11:00:06.565104Z","shell.execute_reply.started":"2025-08-30T11:00:06.549936Z","shell.execute_reply":"2025-08-30T11:00:06.564515Z"}},"outputs":[{"name":"stdout","text":"Her bir şehirden kaç adet veri var:\ncity_name\nMadrid        36267\nBilbao        35951\nSeville       35557\n Barcelona    35476\nValencia      35145\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Her sütundaki eksik değer sayısını kontrol etme\nprint(df.isnull().sum())\n\n# Örneğin, eksik değerleri 0 ile dolduralım (bu durumunuza göre değişebilir)\n# df = df.fillna(0)\n\n# 'city_name', 'weather_id', 'weather_description', 'weather_icon' gibi\n# modelde doğrudan kullanılmayacak sütunları düşürebilirsiniz\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:00:16.606277Z","iopub.execute_input":"2025-08-30T11:00:16.606966Z","iopub.status.idle":"2025-08-30T11:00:16.659644Z","shell.execute_reply.started":"2025-08-30T11:00:16.606941Z","shell.execute_reply":"2025-08-30T11:00:16.658908Z"}},"outputs":[{"name":"stdout","text":"dt_iso                 0\ncity_name              0\ntemp                   0\ntemp_min               0\ntemp_max               0\npressure               0\nhumidity               0\nwind_speed             0\nwind_deg               0\nrain_1h                0\nrain_3h                0\nsnow_3h                0\nclouds_all             0\nweather_id             0\nweather_main           0\nweather_description    0\nweather_icon           0\ndtype: int64\n                      dt_iso city_name     temp  temp_min  temp_max  pressure  \\\n0  2015-01-01 00:00:00+01:00  Valencia  270.475   270.475   270.475      1001   \n1  2015-01-01 01:00:00+01:00  Valencia  270.475   270.475   270.475      1001   \n2  2015-01-01 02:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n3  2015-01-01 03:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n4  2015-01-01 04:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n\n   humidity  wind_speed  wind_deg  rain_1h  rain_3h  snow_3h  clouds_all  \\\n0        77           1        62      0.0      0.0      0.0           0   \n1        77           1        62      0.0      0.0      0.0           0   \n2        78           0        23      0.0      0.0      0.0           0   \n3        78           0        23      0.0      0.0      0.0           0   \n4        78           0        23      0.0      0.0      0.0           0   \n\n   weather_id weather_main weather_description weather_icon  \n0         800        clear        sky is clear          01n  \n1         800        clear        sky is clear          01n  \n2         800        clear        sky is clear          01n  \n3         800        clear        sky is clear          01n  \n4         800        clear        sky is clear          01n  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Her bir şehir için ayrı bir DataFrame oluştur\ncities = df['city_name'].unique()\ncity_dataframes = {city: df[df['city_name'] == city].copy() for city in cities}\n\n# Örnek olarak, ilk şehrin DataFrame'ini görüntüleyelim\nprint(\"İlk şehir verisi:\\n\", list(city_dataframes.keys())[0])\nprint(city_dataframes[list(city_dataframes.keys())[0]].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:00:38.278245Z","iopub.execute_input":"2025-08-30T11:00:38.279097Z","iopub.status.idle":"2025-08-30T11:00:38.374233Z","shell.execute_reply.started":"2025-08-30T11:00:38.279062Z","shell.execute_reply":"2025-08-30T11:00:38.373596Z"}},"outputs":[{"name":"stdout","text":"İlk şehir verisi:\n Valencia\n                      dt_iso city_name     temp  temp_min  temp_max  pressure  \\\n0  2015-01-01 00:00:00+01:00  Valencia  270.475   270.475   270.475      1001   \n1  2015-01-01 01:00:00+01:00  Valencia  270.475   270.475   270.475      1001   \n2  2015-01-01 02:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n3  2015-01-01 03:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n4  2015-01-01 04:00:00+01:00  Valencia  269.686   269.686   269.686      1002   \n\n   humidity  wind_speed  wind_deg  rain_1h  rain_3h  snow_3h  clouds_all  \\\n0        77           1        62      0.0      0.0      0.0           0   \n1        77           1        62      0.0      0.0      0.0           0   \n2        78           0        23      0.0      0.0      0.0           0   \n3        78           0        23      0.0      0.0      0.0           0   \n4        78           0        23      0.0      0.0      0.0           0   \n\n   weather_id weather_main weather_description weather_icon  \n0         800        clear        sky is clear          01n  \n1         800        clear        sky is clear          01n  \n2         800        clear        sky is clear          01n  \n3         800        clear        sky is clear          01n  \n4         800        clear        sky is clear          01n  \n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\n# CSV dosyasını DataFrame olarak okuma\ndf = pd.read_csv('/kaggle/input/weather-features1/weather_features.csv')\n\n# Sıcaklık sütunlarını Kelvin'den Celsius'a dönüştür\ndf['temp_celsius'] = df['temp'] - 273.15\ndf['temp_min_celsius'] = df['temp_min'] - 273.15\ndf['temp_max_celsius'] = df['temp_max'] - 273.15","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:08:51.639484Z","iopub.execute_input":"2025-08-30T11:08:51.639798Z","iopub.status.idle":"2025-08-30T11:08:52.009331Z","shell.execute_reply.started":"2025-08-30T11:08:51.639775Z","shell.execute_reply":"2025-08-30T11:08:52.008715Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Her bir şehir için ayrı bir DataFrame oluştur\ncities = df['city_name'].unique()\ncity_dataframes = {city: df[df['city_name'] == city].copy() for city in cities}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:09:21.228848Z","iopub.execute_input":"2025-08-30T11:09:21.229547Z","iopub.status.idle":"2025-08-30T11:09:21.333601Z","shell.execute_reply.started":"2025-08-30T11:09:21.229525Z","shell.execute_reply":"2025-08-30T11:09:21.333044Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nimport numpy as np\n\n# Kullanılacak özellikler\nfeatures = ['temp_celsius', 'pressure', 'humidity', 'wind_speed', 'clouds_all']\n\n# Her şehir için normalleştirici (scaler) ve veri kümesi saklamak için sözlükler\ncity_scalers = {}\ncity_scaled_data = {}\n\nfor city, city_df in city_dataframes.items():\n    # Sadece sayısal özellikleri seç\n    data = city_df[features].values\n\n    # MinMaxScaler'ı her şehir için ayrı ayrı eğit ve veriyi dönüştür\n    scaler = MinMaxScaler()\n    city_scaled_data[city] = scaler.fit_transform(data)\n    city_scalers[city] = scaler\n\n    print(f\"{city} için verinin şekli: {city_scaled_data[city].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:09:53.457372Z","iopub.execute_input":"2025-08-30T11:09:53.458088Z","iopub.status.idle":"2025-08-30T11:09:53.479377Z","shell.execute_reply.started":"2025-08-30T11:09:53.458067Z","shell.execute_reply":"2025-08-30T11:09:53.478823Z"}},"outputs":[{"name":"stdout","text":"Valencia için verinin şekli: (35145, 5)\nMadrid için verinin şekli: (36267, 5)\nBilbao için verinin şekli: (35951, 5)\n Barcelona için verinin şekli: (35476, 5)\nSeville için verinin şekli: (35557, 5)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def create_sequences(data, window_size):\n    X, y = [], []\n    for i in range(len(data) - window_size):\n        X.append(data[i:(i + window_size), :])\n        y.append(data[i + window_size, 0])\n    return np.array(X), np.array(y)\n\nwindow_size = 24\ncity_X = {}\ncity_y = {}\n\nfor city, scaled_data in city_scaled_data.items():\n    X, y = create_sequences(scaled_data, window_size)\n    city_X[city] = X\n    city_y[city] = y\n    print(f\"{city} için X şekli: {X.shape}, y şekli: {y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:11:17.500969Z","iopub.execute_input":"2025-08-30T11:11:17.501705Z","iopub.status.idle":"2025-08-30T11:11:17.762005Z","shell.execute_reply.started":"2025-08-30T11:11:17.501661Z","shell.execute_reply":"2025-08-30T11:11:17.761245Z"}},"outputs":[{"name":"stdout","text":"Valencia için X şekli: (35121, 24, 5), y şekli: (35121,)\nMadrid için X şekli: (36243, 24, 5), y şekli: (36243,)\nBilbao için X şekli: (35927, 24, 5), y şekli: (35927,)\n Barcelona için X şekli: (35452, 24, 5), y şekli: (35452,)\nSeville için X şekli: (35533, 24, 5), y şekli: (35533,)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"city_X_train, city_X_test = {}, {}\ncity_y_train, city_y_test = {}, {}\n\nfor city in cities:\n    X, y = city_X[city], city_y[city]\n    split_index = int(0.8 * len(X))\n\n    city_X_train[city], city_X_test[city] = X[:split_index], X[split_index:]\n    city_y_train[city], city_y_test[city] = y[:split_index], y[split_index:]\n\n    print(f\"{city} için Eğitim verisi boyutu: {city_X_train[city].shape}\")\n    print(f\"{city} için Test verisi boyutu: {city_X_test[city].shape}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:11:31.408631Z","iopub.execute_input":"2025-08-30T11:11:31.409448Z","iopub.status.idle":"2025-08-30T11:11:31.414732Z","shell.execute_reply.started":"2025-08-30T11:11:31.409416Z","shell.execute_reply":"2025-08-30T11:11:31.413962Z"}},"outputs":[{"name":"stdout","text":"Valencia için Eğitim verisi boyutu: (28096, 24, 5)\nValencia için Test verisi boyutu: (7025, 24, 5)\n\nMadrid için Eğitim verisi boyutu: (28994, 24, 5)\nMadrid için Test verisi boyutu: (7249, 24, 5)\n\nBilbao için Eğitim verisi boyutu: (28741, 24, 5)\nBilbao için Test verisi boyutu: (7186, 24, 5)\n\n Barcelona için Eğitim verisi boyutu: (28361, 24, 5)\n Barcelona için Test verisi boyutu: (7091, 24, 5)\n\nSeville için Eğitim verisi boyutu: (28426, 24, 5)\nSeville için Test verisi boyutu: (7107, 24, 5)\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\n# LSTM modeli mimarisini tanımlayan fonksiyon\ndef create_lstm_model(input_shape):\n    model = Sequential([\n        LSTM(units=50, return_sequences=True, input_shape=input_shape),\n        Dropout(0.2),\n        LSTM(units=50, return_sequences=False),\n        Dropout(0.2),\n        Dense(units=1)  # Tek bir çıktı (sıcaklık tahmini) için\n    ])\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model\n\n# Her şehir için modeli eğitme\ntrained_models = {}\n\nfor city in cities:\n    print(f\"--- {city} için model eğitimi başlıyor ---\")\n    \n    X_train, y_train = city_X_train[city], city_y_train[city]\n    \n    # Modelin giriş şeklini belirle: (zaman adımı, özellik sayısı)\n    input_shape = (X_train.shape[1], X_train.shape[2])\n    \n    # Modeli oluştur\n    model = create_lstm_model(input_shape)\n    \n    # Erken durdurma (overfitting'i önlemek için)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    \n    # Modeli eğit\n    history = model.fit(\n        X_train, \n        y_train, \n        epochs=100, \n        batch_size=32, \n        validation_split=0.1,  # Eğitim verisinin %10'u doğrulama için kullanılacak\n        callbacks=[early_stopping],\n        verbose=1\n    )\n    \n    trained_models[city] = model\n    print(f\"--- {city} için model eğitimi tamamlandı ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:11:46.912028Z","iopub.execute_input":"2025-08-30T11:11:46.912294Z","iopub.status.idle":"2025-08-30T11:19:53.027877Z","shell.execute_reply.started":"2025-08-30T11:11:46.912276Z","shell.execute_reply":"2025-08-30T11:19:53.027244Z"}},"outputs":[{"name":"stdout","text":"--- Valencia için model eğitimi başlıyor ---\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756552307.736179      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756552312.144221     122 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0211 - val_loss: 0.0028\nEpoch 2/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0019\nEpoch 3/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0014\nEpoch 4/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0012\nEpoch 5/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0012\nEpoch 6/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0011\nEpoch 7/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0010\nEpoch 8/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0013\nEpoch 9/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 9.8764e-04\nEpoch 10/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 9.6714e-04\nEpoch 11/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.6139e-04\nEpoch 12/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 9.2819e-04\nEpoch 13/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 9.8138e-04\nEpoch 14/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 0.0011\nEpoch 15/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 8.9646e-04\nEpoch 16/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.9332e-04 - val_loss: 9.1363e-04\nEpoch 17/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 9.6625e-04 - val_loss: 9.9402e-04\nEpoch 18/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.7590e-04 - val_loss: 8.9818e-04\nEpoch 19/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.6580e-04 - val_loss: 8.9874e-04\nEpoch 20/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.6369e-04 - val_loss: 8.8445e-04\nEpoch 21/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.6226e-04 - val_loss: 9.5233e-04\nEpoch 22/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.4242e-04 - val_loss: 8.9833e-04\nEpoch 23/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.3082e-04 - val_loss: 8.8654e-04\nEpoch 24/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.4782e-04 - val_loss: 9.4248e-04\nEpoch 25/100\n\u001b[1m791/791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.1106e-04 - val_loss: 9.0841e-04\n--- Valencia için model eğitimi tamamlandı ---\n--- Madrid için model eğitimi başlıyor ---\nEpoch 1/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0157 - val_loss: 0.0017\nEpoch 2/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 7.8903e-04\nEpoch 3/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 5.9731e-04\nEpoch 4/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 4.6648e-04\nEpoch 5/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 5.5693e-04\nEpoch 6/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 4.5872e-04\nEpoch 7/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 6.1378e-04\nEpoch 8/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 3.1539e-04\nEpoch 9/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 3.0881e-04\nEpoch 10/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.7285e-04 - val_loss: 2.8663e-04\nEpoch 11/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.9260e-04 - val_loss: 6.1055e-04\nEpoch 12/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.5639e-04 - val_loss: 4.9866e-04\nEpoch 13/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.3601e-04 - val_loss: 2.8197e-04\nEpoch 14/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.0244e-04 - val_loss: 5.8157e-04\nEpoch 15/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.0188e-04 - val_loss: 3.1772e-04\nEpoch 16/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.9236e-04 - val_loss: 3.2850e-04\nEpoch 17/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.9496e-04 - val_loss: 3.2334e-04\nEpoch 18/100\n\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.6063e-04 - val_loss: 9.1358e-04\n--- Madrid için model eğitimi tamamlandı ---\n--- Bilbao için model eğitimi başlıyor ---\nEpoch 1/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0096 - val_loss: 0.0015\nEpoch 2/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 9.6055e-04\nEpoch 3/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 7.3525e-04\nEpoch 4/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 6.5171e-04\nEpoch 5/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0010 - val_loss: 6.9225e-04\nEpoch 6/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.5098e-04 - val_loss: 5.9905e-04\nEpoch 7/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.1702e-04 - val_loss: 5.4600e-04\nEpoch 8/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.9724e-04 - val_loss: 5.4441e-04\nEpoch 9/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.4136e-04 - val_loss: 5.6628e-04\nEpoch 10/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.4128e-04 - val_loss: 5.9739e-04\nEpoch 11/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.1358e-04 - val_loss: 9.0179e-04\nEpoch 12/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.2411e-04 - val_loss: 5.3884e-04\nEpoch 13/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.9318e-04 - val_loss: 5.5008e-04\nEpoch 14/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.0074e-04 - val_loss: 5.4750e-04\nEpoch 15/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.8417e-04 - val_loss: 5.7250e-04\nEpoch 16/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.8866e-04 - val_loss: 6.2648e-04\nEpoch 17/100\n\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.7592e-04 - val_loss: 5.5702e-04\n--- Bilbao için model eğitimi tamamlandı ---\n---  Barcelona için model eğitimi başlıyor ---\nEpoch 1/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0149 - val_loss: 0.0019\nEpoch 2/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0013\nEpoch 3/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0011\nEpoch 4/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 8.2049e-04\nEpoch 5/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 6.5734e-04\nEpoch 6/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.7724e-04 - val_loss: 6.1053e-04\nEpoch 7/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.1355e-04 - val_loss: 5.4150e-04\nEpoch 8/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.9732e-04 - val_loss: 4.6147e-04\nEpoch 9/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.2421e-04 - val_loss: 5.3910e-04\nEpoch 10/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4602e-04 - val_loss: 5.1456e-04\nEpoch 11/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.5384e-04 - val_loss: 4.2452e-04\nEpoch 12/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.6675e-04 - val_loss: 4.0941e-04\nEpoch 13/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4298e-04 - val_loss: 4.2069e-04\nEpoch 14/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.2364e-04 - val_loss: 4.4277e-04\nEpoch 15/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3577e-04 - val_loss: 4.5280e-04\nEpoch 16/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.0453e-04 - val_loss: 8.2493e-04\nEpoch 17/100\n\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4296e-04 - val_loss: 5.5825e-04\n---  Barcelona için model eğitimi tamamlandı ---\n--- Seville için model eğitimi başlıyor ---\nEpoch 1/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0145 - val_loss: 0.0022\nEpoch 2/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0015\nEpoch 3/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0012\nEpoch 4/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0012\nEpoch 5/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 8.0000e-04\nEpoch 6/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 7.9100e-04\nEpoch 7/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 7.5509e-04\nEpoch 8/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 0.0011\nEpoch 9/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 5.9136e-04\nEpoch 10/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 8.7660e-04\nEpoch 11/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 7.2544e-04\nEpoch 12/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 6.3717e-04\nEpoch 13/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 6.7486e-04\nEpoch 14/100\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 6.7222e-04\n--- Seville için model eğitimi tamamlandı ---\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# Kullanılan özellikler, MinMaxScaler'dan doğru tersine dönüştürme için gerekli\nfeatures = ['temp_celsius', 'pressure', 'humidity', 'wind_speed', 'clouds_all']\n\nfor city in cities:\n    print(f\"\\n--- {city} için model performansı değerlendiriliyor ---\")\n    \n    model = trained_models[city]\n    X_test, y_test = city_X_test[city], city_y_test[city]\n    \n    # Tahminleri yap\n    y_pred_scaled = model.predict(X_test)\n    \n    # Tahminleri ve gerçek değerleri orijinal birime (Celsius) dönüştürme\n    # Normalleştirme işlemi tüm özellikler için yapıldığı için,\n    # tersine dönüştürme için geçici bir matris oluşturmamız gerekir.\n    \n    dummy_array_pred = np.zeros((len(y_pred_scaled), len(features)))\n    dummy_array_pred[:, 0] = y_pred_scaled.flatten()\n    y_pred = city_scalers[city].inverse_transform(dummy_array_pred)[:, 0]\n    \n    dummy_array_true = np.zeros((len(y_test), len(features)))\n    dummy_array_true[:, 0] = y_test.flatten()\n    y_test_original = city_scalers[city].inverse_transform(dummy_array_true)[:, 0]\n    \n    # Hata hesaplama\n    mse = mean_squared_error(y_test_original, y_pred)\n    rmse = np.sqrt(mse)\n    \n    print(f\"{city} için Test MSE: {mse:.4f}\")\n    print(f\"{city} için Test RMSE: {rmse:.4f} °C\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:20:54.145862Z","iopub.execute_input":"2025-08-30T11:20:54.146141Z","iopub.status.idle":"2025-08-30T11:20:59.743750Z","shell.execute_reply.started":"2025-08-30T11:20:54.146123Z","shell.execute_reply":"2025-08-30T11:20:59.743186Z"}},"outputs":[{"name":"stdout","text":"\n--- Valencia için model performansı değerlendiriliyor ---\n\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nValencia için Test MSE: 0.9648\nValencia için Test RMSE: 0.9822 °C\n\n--- Madrid için model performansı değerlendiriliyor ---\n\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nMadrid için Test MSE: 0.8934\nMadrid için Test RMSE: 0.9452 °C\n\n--- Bilbao için model performansı değerlendiriliyor ---\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nBilbao için Test MSE: 0.7722\nBilbao için Test RMSE: 0.8788 °C\n\n---  Barcelona için model performansı değerlendiriliyor ---\n\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n Barcelona için Test MSE: 0.9906\n Barcelona için Test RMSE: 0.9953 °C\n\n--- Seville için model performansı değerlendiriliyor ---\n\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nSeville için Test MSE: 1.1352\nSeville için Test RMSE: 1.0654 °C\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Veri setini yükle ve ön işlemeden geçir\ndf = pd.read_csv('/kaggle/input/weather-features1/weather_features.csv')\n\n# `dt_iso` sütununu datetime tipine dönüştür ve indeksi olarak ayarla\ndf['dt_iso'] = pd.to_datetime(df['dt_iso'])\ndf = df.set_index('dt_iso')\n\n# Sıcaklıkları Kelvin'den Celsius'a dönüştür\ndf['temp_celsius'] = df['temp'] - 273.15\n\n# Veriyi şehirlere göre ayır\ncities = df['city_name'].unique()\ncity_dataframes = {city: df[df['city_name'] == city].copy() for city in cities}\n\n# LSTM modeli için kullanılacak özellikler\nfeatures = ['temp_celsius', 'pressure', 'humidity', 'wind_speed', 'clouds_all']\n\n# Her şehir için veriyi normalleştirme\nfrom sklearn.preprocessing import MinMaxScaler\ncity_scalers = {}\ncity_scaled_data = {}\n\nfor city, city_df in city_dataframes.items():\n    data = city_df[features].values\n    scaler = MinMaxScaler()\n    city_scaled_data[city] = scaler.fit_transform(data)\n    city_scalers[city] = scaler\n\n# LSTM için X ve y dizilerini oluşturma fonksiyonu\ndef create_sequences(data, window_size):\n    X, y = [], []\n    for i in range(len(data) - window_size):\n        X.append(data[i:(i + window_size), :])\n        y.append(data[i + window_size, 0])\n    return np.array(X), np.array(y)\n\nwindow_size = 24\ncity_X = {}\ncity_y = {}\nfor city, scaled_data in city_scaled_data.items():\n    X, y = create_sequences(scaled_data, window_size)\n    city_X[city] = X\n    city_y[city] = y\n\n# Eğitim ve test setlerini ayırma\ncity_X_train, city_X_test = {}, {}\ncity_y_train, city_y_test = {}, {}\n\nfor city in cities:\n    X, y = city_X[city], city_y[city]\n    split_index = int(0.8 * len(X))\n    city_X_train[city], city_X_test[city] = X[:split_index], X[split_index:]\n    city_y_train[city], city_y_test[city] = y[:split_index], y[split_index:]\n\n# Eğitilmiş modellerin yüklü olduğunu varsayıyoruz.\n\n# Tahmin yapmak istediğimiz şehri ve tarihi belirle\ncity = 'Valencia'\n# Tahmin tarihini veri setinde olan bir tarihle değiştiriyoruz\nprediction_time = pd.to_datetime('2017-11-30 14:00:00+01:00')\n\n# Girdi verisi için önceki 24 saatlik aralığı belirle\ninput_end_time = prediction_time - pd.Timedelta(hours=1)\ninput_start_time = prediction_time - pd.Timedelta(hours=24)\n\n# Veri setinden ilgili 24 saatlik veriyi al\ninput_data = city_dataframes[city].loc[input_start_time:input_end_time]\ninput_data_features = input_data[features].values\n\n# Veriyi normalleştirici ile dönüştür\nscaler = city_scalers[city]\ninput_scaled = scaler.transform(input_data_features)\n\n# LSTM için 3 boyutlu şekle dönüştür (1 örnek, 24 zaman adımı, 5 özellik)\nX_predict = input_scaled.reshape(1, 24, len(features))\n\n# Eğitilmiş modeli kullanarak tahmini yap\n# trained_models sözlüğünüzün doğru şekilde eğitilmiş modelleri içerdiğini varsayar.\npredicted_scaled_temp = trained_models[city].predict(X_predict)\n\n# Tahmini orijinal sıcaklık birimine (Celsius) geri dönüştür\ndummy_array = np.zeros((1, len(features)))\ndummy_array[0, 0] = predicted_scaled_temp[0, 0]\npredicted_temp_celsius = scaler.inverse_transform(dummy_array)[0, 0]\n\n# Gerçek değeri veri setinden al ve karşılaştır\ntry:\n    actual_temp_celsius = city_dataframes[city].loc[prediction_time]['temp_celsius']\n    \n    print(\"--- Tahmin Sonucu ---\")\n    print(f\"Tahmin Edilen Sıcaklık ({prediction_time}): {predicted_temp_celsius:.2f} °C\")\n    print(f\"Gerçek Sıcaklık ({prediction_time}): {actual_temp_celsius:.2f} °C\")\n    print(f\"Fark: {abs(predicted_temp_celsius - actual_temp_celsius):.2f} °C\")\n\nexcept KeyError:\n    print(f\"'{prediction_time}' için veri setinde gerçek değer bulunamadı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:44:45.226448Z","iopub.execute_input":"2025-08-30T11:44:45.226989Z","iopub.status.idle":"2025-08-30T11:44:50.030563Z","shell.execute_reply.started":"2025-08-30T11:44:45.226966Z","shell.execute_reply":"2025-08-30T11:44:50.030013Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/4269288452.py:8: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n  df['dt_iso'] = pd.to_datetime(df['dt_iso'])\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n--- Tahmin Sonucu ---\nTahmin Edilen Sıcaklık (2017-11-30 14:00:00+01:00): 14.14 °C\nGerçek Sıcaklık (2017-11-30 14:00:00+01:00): 14.00 °C\nFark: 0.14 °C\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import os\n\n# Kaydedilecek dizini oluşturun (eğer yoksa)\n# Bu adım, dosyaların nereye kaydedileceğini belirler.\nif not os.path.exists('trained_models'):\n    os.makedirs('trained_models')\n\nprint(\"Modeller kaydediliyor...\")\n\nfor city, model in trained_models.items():\n    # Dosya adını belirle\n    file_name = f'trained_models/lstm_model_{city}.h5'\n    \n    # Modeli kaydet\n    model.save(file_name)\n    \n    print(f\"'{city}' için model '{file_name}' dosyasına kaydedildi.\")\n\nprint(\"\\nTüm modeller başarıyla kaydedildi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:46:31.260314Z","iopub.execute_input":"2025-08-30T11:46:31.260937Z","iopub.status.idle":"2025-08-30T11:46:31.385951Z","shell.execute_reply.started":"2025-08-30T11:46:31.260912Z","shell.execute_reply":"2025-08-30T11:46:31.385188Z"}},"outputs":[{"name":"stdout","text":"Modeller kaydediliyor...\n'Valencia' için model 'trained_models/lstm_model_Valencia.h5' dosyasına kaydedildi.\n'Madrid' için model 'trained_models/lstm_model_Madrid.h5' dosyasına kaydedildi.\n'Bilbao' için model 'trained_models/lstm_model_Bilbao.h5' dosyasına kaydedildi.\n' Barcelona' için model 'trained_models/lstm_model_ Barcelona.h5' dosyasına kaydedildi.\n'Seville' için model 'trained_models/lstm_model_Seville.h5' dosyasına kaydedildi.\n\nTüm modeller başarıyla kaydedildi.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Yüklemek istediğiniz şehrin modelini belirleyin\ncity_to_load = 'Valencia'\nfile_name = f'trained_models/lstm_model_{city_to_load}.h5'\n\n# Modeli yükle\nloaded_model = load_model(file_name)\n\nprint(f\"'{city_to_load}' modeli başarıyla yüklendi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T11:48:45.912259Z","iopub.execute_input":"2025-08-30T11:48:45.912549Z","iopub.status.idle":"2025-08-30T11:48:45.983556Z","shell.execute_reply.started":"2025-08-30T11:48:45.912530Z","shell.execute_reply":"2025-08-30T11:48:45.982861Z"}},"outputs":[{"name":"stdout","text":"'Valencia' modeli başarıyla yüklendi.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"1. Data Preparation and Preprocessing\nYour project's foundation was built on solid data preparation. You took the raw dataset and made it ready for analysis:\n\nDataset Loading: You loaded the file containing the weather data.\n\nDate-Time Conversion: You correctly converted the date and time data in the dt_iso column into the datetime format and set it as the index of the dataset. This was a critical step for time-based analysis.\n\nUnit Conversion: You converted the temperatures from Kelvin to Celsius to make the predictions more understandable.\n\nCity-Based Segregation: You separated the data into individual DataFrames for each of the 5 cities, paving the way for training models tailored to each city's unique dynamics.\n\n2. Model Training: LSTM Neural Network\nIn the core of the project, you used an LSTM (Long Short-Term Memory) neural network, a deep learning model specialized in time series data.\n\nFor each city, you trained a specific model to predict the temperature of the next hour based on the past 24 hours of data (temperature, humidity, pressure, etc.).\n\nThese models successfully learned the complex sequential patterns within the weather data.\n\n3. Model Performance and Success Evaluation\nThe models you trained showed strong performance on test data they had never seen before. The RMSE (Root Mean Squared Error) values, which indicate the accuracy of your predictions, proved the project's success.\n\nOverall Success: The average error of all your models was less than 1 °C. This is an excellent result for a variable task like weather forecasting.\n\nBest-Performing Model: The model trained for Bilbao delivered the most accurate predictions with an average error of only 0.87 °C.\n\n4. Practical Forecasting and Model Limitations\nYou tested how your model would perform under real-world conditions.\n\nSingle-Point Prediction: You demonstrated how the model can successfully predict the future based on past data by forecasting a specific random date (e.g., 2017-01-01).\n\nModel Limitations: You learned that the model cannot predict dates it has never seen (e.g., the year 2025). A time series model's \"tomorrow\" is always relative to its last available data point. Since your dataset ended in 2017, your model's predictions were limited to that timeframe.\n\n5. Final Product: Saved Models\nFinally, you turned all this work into a practical product. You saved each city's trained model to disk in the .h5 format so they can be reused without needing to be re-trained. This shows that your project has a reusable and sustainable output.\n\nYour project successfully covered all the fundamental steps of a data science project, from data cleaning and modeling to interpreting the results.\n","metadata":{}},{"cell_type":"markdown","source":"1. Veri Hazırlığı ve Ön İşleme\nProjenizin temelini sağlam bir veri hazırlığı oluşturdu. Ham veri setini alarak onu analiz edilebilir hale getirdiniz:\n\nVeri Seti Yükleme: Hava durumu verilerini içeren dosyayı yüklediniz.\n\nTarih-Saat Dönüşümü: dt_iso sütunundaki tarih ve saat verilerini doğru şekilde datetime formatına dönüştürdünüz ve veri setinin indeksi olarak belirlediniz. Bu, zaman tabanlı analizler için kritik bir adımdı.\n\nBirim Dönüşümü: Sıcaklıkları, tahminlerin daha anlaşılır olması için Kelvin'den Celsius'a çevirdiniz.\n\nŞehir Bazlı Ayrıştırma: Veriyi her bir şehir için ayrı DataFrame'lere ayırarak her şehrin kendi dinamiklerine uygun modeller eğitmenin yolunu açtınız.\n\n2. Model Eğitimi: LSTM Sinir Ağı\nProjenin en önemli kısmı olan model eğitiminde, zaman serisi verilerinde uzmanlaşmış bir derin öğrenme modeli olan LSTM (Uzun-Kısa Süreli Hafıza) sinir ağını kullandınız.\n\nHer bir şehir için, geçmiş 24 saatlik veriye (sıcaklık, nem, basınç vb.) bakarak bir sonraki saatteki sıcaklığı tahmin etmesi için özel bir model eğittiniz.\n\nBu modeller, hava durumu verisindeki karmaşık ardışık kalıpları başarıyla öğrendi.\n\n3. Model Performansı ve Başarı Değerlendirmesi\nEğittiğiniz modeller, daha önce hiç görmedikleri test verileri üzerinde güçlü bir performans gösterdi. Modelinizin ne kadar doğru tahminler yaptığını gösteren RMSE (Ortalama Karesel Hatanın Karekökü) değerleri, projenin başarısını kanıtladı.\n\nGenel Başarı: Tüm modellerinizin ortalama hata payı 1 °C'nin altında kaldı. Bu, hava durumu tahmini gibi değişken bir görev için mükemmel bir sonuçtur.\n\nEn İyi Model: Bilbao için eğitilen model, ortalama sadece 0.87 °C'lik bir hata payıyla en isabetli tahminleri yaptı.\n\n4. Pratik Tahmin ve Model Sınırları\nModelinizin gerçek dünya koşullarında nasıl çalıştığını test ettiniz.\n\nTek Nokta Tahmini: Veri setinizdeki rastgele bir tarihi (örneğin, 2017-01-01) kullanarak, modelin geçmiş verilere dayanarak geleceği nasıl başarıyla tahmin ettiğini gördünüz.\n\nModel Sınırları: Modelin, eğitiminde hiç görmediği tarihler (örneğin 2025 yılı) için tahmin yapamayacağını öğrendiniz. Bir zaman serisi modelinin \"yarını\", her zaman elindeki en son veri noktasına göre belirlenir. Veri setiniz 2017'de bittiği için, modelinizin tahmini de o tarihlerle sınırlı kaldı.\n\n5. Nihai Ürün: Kaydedilmiş Modeller\nSon olarak, tüm bu çalışmaları pratik bir ürüne dönüştürdünüz. Eğittiğiniz her bir şehre ait modeli, daha sonra yeniden eğitim yapmaya gerek kalmadan kullanabilmek için disk üzerine .h5 formatında kaydettiniz. Bu, projenizin yeniden kullanılabilir ve sürdürülebilir bir çıktıya sahip olduğunu gösterir.\n\nBu projeniz, veri temizleme, modelleme ve çıktıları yorumlama gibi bir veri bilimi projesinin tüm aşamalarını başarıyla kapsadı.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}